# -*- coding: utf-8 -*-
"""Awaves.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vUPBy2Gp_kdt6LAP0fVooGqEGRlFMwBT
"""

# from google.colab import drive
# drive.mount('/content/drive')

import pandas as pd
import librosa as lb
import numpy as np
import sklearn
import librosa
import librosa.display
import matplotlib.pyplot as plt
import pickle

# SB_CNN implemented from this paper - https://arxiv.org/pdf/1608.04363.pdf
#import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Reshape
from tensorflow.keras.layers import Conv2D, MaxPool2D
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.regularizers import l2
import itertools
import numpy as np
from sklearn import metrics
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from os import listdir
from os.path import isfile, join
from tensorflow.keras import optimizers
#from src.config import *
#from src.explore import get_data

def SBCNN_Model(field_size, bands, frames, num_channels, num_labels):
    model = Sequential()

    model.add(Conv2D(24, field_size, field_size, padding='same', activation = 'relu', input_shape=(bands, frames, num_channels)))
    model.add(MaxPool2D(pool_size=(4, 2)))

    model.add(Conv2D(48, field_size, field_size, padding='same', activation = 'relu'))
    model.add(MaxPool2D(pool_size=(4, 2)))

    model.add(Conv2D(48, field_size, field_size, padding='valid', activation = 'relu'))

    model.add(Flatten())
    model.add(Dropout(0.5))
    model.add(Dense(64, activation = 'relu', kernel_regularizer = l2(0.001)))
    model.add(Dropout(0.5))
    model.add(Dense(num_labels, activation = 'softmax', kernel_regularizer = l2(0.001)))

    model.summary()

    return model

# create mel-spectrogram
#single_song_path = '/content/drive/MyDrive/Awaves Data/set1/mp3/SmallerSet/001.mp3'
single_song_path = '/Users/satyakimallick/IdeaProjects/Awaves_Energy_Levels/dataset/University of Jyvaskyla emotion dataset/set1/mp3/Soundtrack360_mp3/001.mp3'

y, sr = librosa.load(single_song_path)
S = librosa.feature.melspectrogram(y=y, sr=sr)

fig, ax = plt.subplots()
S_dB = librosa.power_to_db(S, ref=np.max) #should I use powerToDB or AplitudeToDB ?
img = librosa.display.specshow(S_dB, x_axis='time',
                         y_axis='mel', sr=sr,
                         fmax=8000, ax=ax)
fig.colorbar(img, ax=ax, format='%+2.0f dB')
ax.set(title='Mel-frequency spectrogram')

# base_dir = '/content/drive/MyDrive/Awaves Data/set1/'
base_dir = '/Users/satyakimallick/IdeaProjects/Awaves_Energy_Levels/dataset/University of Jyvaskyla emotion dataset/set1/'

def audio_to_spectogram(audio_file):
  y, sr = librosa.load(audio_file)
  S1 = librosa.feature.melspectrogram(y = y, sr = sr)


  return librosa.power_to_db(S1, ref = np.max)


def divide_song(y, sr):
    return y[:110250], y[110250:220500]

# Read the audio files and convert to spectograms

try:
    # Check if pickle file exists
    X = pickle.load(open("X.pickle", "rb"))
except (OSError, IOError) as e:

    songs_path = f'{base_dir}mp3/Soundtrack360_mp3/'
    audio_files = [f for f in listdir(songs_path) if isfile(join(songs_path, f))]
    audio_files.sort()
    print(audio_files)
    X = [audio_to_spectogram(songs_path + file) for file in audio_files] # This takes a shit load of time




    pickle.dump(X, open("X.pickle", "wb"))


# Read the targets
from sklearn.preprocessing import LabelBinarizer
import pandas as pd
target_path = f'{base_dir}mean_ratings_set1.xls'
targets = pd.read_excel(target_path, usecols = "J")

encoder = LabelBinarizer()
targets = encoder.fit_transform(targets['TARGET'])
y = targets 
print(y.shape)



X = np.asarray(X)


def test_model():
  model = Sequential()
  model.add(Reshape((275840,), input_shape=(5, 128, 431)))
  model.add(Dense(1500, activation='relu'))
  model.add(Dense(500, activation='relu'))
  model.add(Dense(10, activation='softmax'))
  model.compile(optimizer='SGD',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
  return model

def SBCNN():  
  model = Sequential()

  model.add(Conv2D(24, kernel_size=(5, 5), strides=(1, 1), padding='same', activation = 'relu', input_shape=(128, 431, 1)))
  model.add(MaxPool2D(pool_size=(2, 2)))

  model.add(Conv2D(48, kernel_size=(5, 5), strides=(1, 1), padding='same', activation = 'relu'))
  model.add(MaxPool2D(pool_size=(2, 2)))

  model.add(Conv2D(48, kernel_size=(5, 5), strides=(1, 1), padding='valid', activation = 'relu'))

  model.add(Flatten())
  model.add(Dropout(0.5))
  model.add(Dense(64, activation = 'relu', kernel_regularizer = l2(0.001)))
  model.add(Dropout(0.5))
  model.add(Dense(1, activation = 'softmax', kernel_regularizer = l2(0.001)))
  model.compile(optimizer=optimizers.SGD(), loss='categorical_crossentropy', metrics=['accuracy'])
  return model


X = X.reshape(360, 128, 431, 1)


my_model = SBCNN()

my_model.summary()

def generate_data(len):

    for i in range(len):
      yield X_train[i].reshape(1,128,431,1), y_train[i]


def get_data():
  return train_test_split(X, y, test_size = 0.9, shuffle = True, stratify=y)

X_train, X_test, y_train, y_test = get_data()

generator = generate_data(X_train.shape[0])
for i in generator:
    print(i[1])


my_model.fit(generate_data(X_train.shape[0]), epochs=3)